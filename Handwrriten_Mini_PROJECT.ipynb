{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNNaD1HXQqRI",
        "outputId": "9bd67953-b800-4fcd-a4da-b322eac66e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_path = '/content/drive/MyDrive/dataset/orininal'\n",
        "forge_path ='/content/drive/MyDrive/dataset/fraud'"
      ],
      "metadata": {
        "id": "YrhRt2A6UjcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(real_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHrMIEMQVEzv",
        "outputId": "49b9e673-904d-4e9d-c5d9-2590c7641494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset/orininal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "G9DQzt1DadAk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m27UJSRzQEhN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_images = []\n",
        "for img_name in os.listdir(real_path):\n",
        "    img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    real_images.append(img)\n",
        "real_images = np.array(real_images, dtype=object)\n",
        "\n",
        "forge_images = []\n",
        "for img_name in os.listdir(forge_path):\n",
        "    img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    forge_images.append(img)\n",
        "forge_images = np.array(forge_images, dtype=object)"
      ],
      "metadata": {
        "id": "MK_vjwCVRr4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_labels = np.zeros(real_images.shape[0])\n",
        "forge_labels = np.ones(forge_images.shape[0])\n",
        "\n",
        "X = np.concatenate((real_images, forge_images), axis=0)\n",
        "y = np.concatenate((real_labels, forge_labels), axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "b1KwDCUMWVV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COMPLETE CNN MODEL\n"
      ],
      "metadata": {
        "id": "PdZCJM0PbRrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7GSN81BbaxFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Define the paths to the real and forged signature images\n",
        "real_path = '/content/drive/MyDrive/dataset/orininal'\n",
        "forged_path ='/content/drive/MyDrive/dataset/fraud'\n",
        "\n",
        "# Load the real signature images\n",
        "real_images = []\n",
        "for filename in os.listdir(real_path):\n",
        "    image = cv2.imread(os.path.join(real_path, filename))\n",
        "    if image is not None:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        real_images.append(image)\n",
        "\n",
        "# Load the forged signature images\n",
        "forged_images = []\n",
        "for filename in os.listdir(forged_path):\n",
        "    image = cv2.imread(os.path.join(forged_path, filename))\n",
        "    if image is not None:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        forged_images.append(image)\n",
        "\n",
        "# Convert the images to numpy arrays\n",
        "real_images = np.array(real_images)\n",
        "forged_images = np.array(forged_images)\n",
        "\n",
        "# Create the labels (0 for real, 1 for forged)\n",
        "real_labels = np.zeros((real_images.shape[0], 1))\n",
        "forged_labels = np.ones((forged_images.shape[0], 1))\n",
        "\n",
        "# Concatenate the real and forged images and labels\n",
        "images = np.concatenate((real_images, forged_images))#X\n",
        "labels = np.concatenate((real_labels, forged_labels))#y\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(train_images.reshape((-1, 224, 224, 1)), train_labels, batch_size=64, epochs=20, validation_data=(val_images.reshape((-1, 224, 224, 1)), val_labels))\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(val_images.reshape((-1, 224, 224, 1)), val_labels)\n",
        "print('Validation accuracy:', accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoLKxf4ZcTis",
        "outputId": "57379642-85f2-41ab-e6fb-24ba7b46d648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 8s 8s/step - loss: 11.9727 - accuracy: 0.5500 - val_loss: 1170.8154 - val_accuracy: 0.7000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 2110.3750 - accuracy: 0.4500 - val_loss: 380.5065 - val_accuracy: 0.7000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 683.9683 - accuracy: 0.4500 - val_loss: 262.6178 - val_accuracy: 0.3000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 6s 6s/step - loss: 165.8748 - accuracy: 0.5500 - val_loss: 111.9043 - val_accuracy: 0.3000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 6s 6s/step - loss: 70.4085 - accuracy: 0.5500 - val_loss: 12.8844 - val_accuracy: 0.7000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 7s 7s/step - loss: 22.3752 - accuracy: 0.4500 - val_loss: 13.9840 - val_accuracy: 0.3000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 8.7162 - accuracy: 0.5500 - val_loss: 9.4563 - val_accuracy: 0.7000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 16.3184 - accuracy: 0.4500 - val_loss: 8.4506 - val_accuracy: 0.3000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 5.1185 - accuracy: 0.5500 - val_loss: 5.5026 - val_accuracy: 0.7000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 8.7883 - accuracy: 0.4500 - val_loss: 10.9951 - val_accuracy: 0.3000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 6.6784 - accuracy: 0.5500 - val_loss: 1.8101 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.9060 - accuracy: 0.7250 - val_loss: 8.5335 - val_accuracy: 0.7000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 13.9396 - accuracy: 0.4500 - val_loss: 2.5149 - val_accuracy: 0.7000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.3336 - accuracy: 0.4500 - val_loss: 12.9944 - val_accuracy: 0.3000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 7.6351 - accuracy: 0.5500 - val_loss: 7.0575 - val_accuracy: 0.3000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 3.8729 - accuracy: 0.5500 - val_loss: 2.8052 - val_accuracy: 0.7000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.8896 - accuracy: 0.4500 - val_loss: 4.8949 - val_accuracy: 0.3000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 2.3364 - accuracy: 0.5500 - val_loss: 0.7625 - val_accuracy: 0.7000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4243 - accuracy: 0.7000 - val_loss: 0.6516 - val_accuracy: 0.6000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2043 - accuracy: 0.8750 - val_loss: 1.0072 - val_accuracy: 0.7000\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 1.0072 - accuracy: 0.7000\n",
            "Validation accuracy: 0.699999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/dataset/orininal/su5_1.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (224, 224))\n",
        "img = np.array(img).reshape(-1, 224, 224, 1) / 255.0\n",
        "\n",
        "# Predict the class of the signature image\n",
        "prediction = model.predict(img)\n",
        "print(prediction)\n",
        "if prediction < 0.5046:\n",
        "    print(\"The signature is real.\")\n",
        "else:\n",
        "    print(\"The signature is forged.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk8SVcGOej3Q",
        "outputId": "974b1c13-6e1e-447f-c36b-355671444654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step\n",
            "[[0.50345105]]\n",
            "The signature is real.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, save_model\n",
        "save_model(model, 'image.hdf5')  # Save the trained model to a file\n",
        "print(\"Model Saved\")  # Print model saved message"
      ],
      "metadata": {
        "id": "PHToyZCYfCcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9e2e70-95a6-463b-ed45-5c8704c69246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5ac0bccdb4cb>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(model, 'image.hdf5')  # Save the trained model to a file\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sz_Q90pzDyna"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}